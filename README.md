# oneChatGPT
- oneChatbot_gpt2-vietnamese_fine-tune.py
- Author: Mr.Jack _ CÃ´ng ty www.BICweb.vn
- Date: 24 August 2023

chatGPT siÃªu siÃªu nhá», huáº¥n luyá»‡n chá»‰ vá»›i 1 cÃ¢u duy nháº¥t, vÃ  chá»‰ trong 1 phÃºt (chatGPT super super tiny ... training with only one sentence dataset in one minute !)

"VÃ o ngÃ y 21/08/2023, CÃ´ng ty Cá»• pháº§n VinBigdata cÃ´ng bá»‘ xÃ¢y dá»±ng thÃ nh cÃ´ng mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n tiáº¿ng Viá»‡t, Ä‘áº·t ná»n mÃ³ng cho viá»‡c xÃ¢y dá»±ng cÃ¡c giáº£i phÃ¡p tÃ­ch há»£p AI táº¡o sinh..." 
https://genk.vn/vinbigdata-phat-trien-cong-nghe-ai-tao-sinh-se-som-cho-ra-mat-chatgpt-phien-ban-viet-20230821140700664.chn

ÄÃ¢y cÅ©ng cÃ³ thá»ƒ coi lÃ  má»™t sá»± kiá»‡n lá»›n cá»§a dÃ¢n ngÃ nh IT nÃ³i chung vÃ  dÃ¢n láº­p trÃ¬nh "ngÃ nh" chatGPT nÃ³i riÃªng, vÃ  cháº¯c cÃ³ láº½ "dÃ¢n ngÃ nh" nÃ o cÅ©ng mong muá»‘n lÃ m Ä‘Æ°á»£c ra má»™t em chatGPT nhÆ° váº­y ^^

NhÆ°ng Ä‘á»‘i vá»›i ká»¹ sÆ° láº­p trÃ¬nh khi má»›i bÆ°á»›c vÃ o tháº¿ giá»›i chatGPT thÃ´ng thÆ°á»ng sáº½ cÃ³ nhá»¯ng bÄƒn khoÄƒn sau:
1. MÃ¬nh cÃ³ thá»ƒ triá»ƒn khai Ä‘Æ°á»£c 1 em chatGPT cháº¡y Ä‘Æ°á»£c á»Ÿ nhÃ  khÃ´ng?
2. Cáº§n chuáº©n bá»‹ mÃ¡y mÃ³c cáº¥u hÃ¬nh pháº£i máº¡nh cá»¡ nÃ o?
3. Khá»‘i dá»¯ liá»‡u chuáº©n bá»‹ huáº¥n luyá»‡n lá»›n Ä‘áº¿n Ä‘Ã¢u?
4. Tiáº¿ng Viá»‡t thÃ¬ cÃ³ khÃ³ huáº¥n luyá»‡n khÃ´ng?
5. PhÆ°Æ¡ng phÃ¡p huáº¥n luyá»‡n ra sao?
6. Thá»i gian huáº¥n luyá»‡n trong bao lÃ¢u? 
7. Äá»™ chÃ­nh xÃ¡c cÃ¢u tráº£ lá»i ra sao?
8. Bao giá» sáº½ thá»±c hiá»‡n Ä‘Æ°á»£c Ä‘iá»u Ä‘Ã³?

==> ThÃ´ng thÆ°á»ng thÃ¬ cÃ¢u tráº£ lá»i sáº½ lÃ  ... KhÃ´ng biáº¿t ^^


VÃ¬ váº­y mÃ  hÃ´m nay mÃ¬nh chia sáº» vá»›i cÃ¡c báº¡n má»™t em chatGPT siÃªu.. siÃªu.. siÃªu nhá», Ä‘á»ƒ cÃ¡c báº¡n cÃ¹ng tÃ¬m hiá»ƒu vÃ  chÆ¡i vá»›i em nÃ³ nhÃ© ^^

- Má»¥c Ä‘Ã­ch: NghiÃªn cá»©u há»c táº­p
- NgÃ´n ngá»¯ láº­p trÃ¬nh: Python
- Äá»™ dÃ i mÃ£ nguá»“n: 55 dÃ²ng code ^^
- Model pretrained: GPT2

- NgÃ´n ngá»¯ huáº¥n luyá»‡n: Tiáº¿ng Viá»‡t
- Dá»¯ liá»‡u huáº¥n luyá»‡n: Chá»‰ 01 cÃ¢u duy nháº¥t ^^
- MÃ¡y huáº¥n luyá»‡n: 01 laptop sinh viÃªn
- Thá»i gian huáº¥n luyá»‡n: 01 phÃºt
- Äá»™ tráº£ lá»i chÃ­nh xÃ¡c: 100%

Äá»ƒ thá»­ nghiá»‡m hÃ£y download file vÃ  cháº¡y cÃ¢u lá»‡nh:
$ python oneChatbot_gpt2-vietnamese_fine-tune.py

![alt text](https://github.com/Mr-Jack-Tung/oneChatGPT/blob/main/oneChatbot_Screenshot%202023-08-24%20at%2011.30.png)

Hy vá»ng Ä‘iá»u nÃ y sáº½ giÃºp cÃ¡c báº¡n thÃªm tá»± tin trÃªn con Ä‘Æ°á»ng láº­p trÃ¬nh chinh phá»¥c chatGPT nhÃ©! ^^

------------------------------
**Update**: Monday,25/09/2023 ~> Bao nhiÃªu Parameters lÃ  Ä‘á»§ Ä‘á»ƒ fine-tune 1 cÃ¢u tiáº¿ng Viá»‡t chÃ­nh xÃ¡c ?

MÃ¬nh Ä‘Ã£ thá»­ fine-tune vá»›i model 'huggingface.co/roneneldan/TinyStories-33M', chá»‰ vá»›i 4 x GPTNeoBlock(features=768), cÃ³ sá»‘ lÆ°á»£ng tham sá»‘ lÃ  33 triá»‡u, nhá» hÆ¡n nhiá»u so vá»›i model gpt2 (124M), Ä‘Æ°á»£c Ä‘Ã¡nh giÃ¡ lÃ  cÃ³ cháº¥t lÆ°á»£ng khÃ¡ tá»‘t vá»›i tá»‘c Ä‘á»™ train nhanh hÆ¡n (https://arxiv.org/abs/2305.07759), nhÆ°ng khi thá»­ nghiá»‡m thÃ¬ káº¿t quáº£ cÅ©ng á»•n vá»›i model 'TinyStories-33M', cÃ²n cÃ¡c model vá»›i sá»‘ lÆ°á»£ng params Ã­t hÆ¡n (nhÆ° model 1M, 3M, 8M, 21M) thÃ¬ khÃ´ng ok ^^

Update code:
- from transformers import AutoTokenizer, AutoModelForCausalLM
- model = AutoModelForCausalLM.from_pretrained('roneneldan/TinyStories-33M')
- tokenizer = AutoTokenizer.from_pretrained('EleutherAI/gpt-neo-125M')

Result:
- model_name = 'roneneldan/TinyStories-33M'
- lr=5e-4
- (0.665s) Epoch 29, Loss 0.115172
- Question: Xin chÃ o Answer: CÃ´ng ty BICweb kÃ­nh chÃ o quÃ½ khÃ¡ch!

With Emoji:
- model_name = 'roneneldan/TinyStories-33M'
- lr=6e-4
- qa_pair = 'Question: Xin chÃ o Answer: CÃ´ng ty BICweb kÃ­nh chÃ o quÃ½ khÃ¡ch ğŸ¤—.'
- (0.662s) Epoch 49, Loss 0.099960
- Question: Xin chÃ o Answer: CÃ´ng ty BICweb kÃ­nh chÃ o quÃ½ khÃ¡ch ğŸ¤—

------------------------------
**Update**: Sunday,15/10/2023 ~> CÃ³ thá»ƒ huáº¥n luyá»‡n cho gpt2 hiá»ƒu Ä‘Æ°á»£c hÃ¬nh áº£nh khÃ´ng?

NgÃ y 25/09/2023 vá»«a rá»“i OpenAI cÃ³ thÃ´ng bÃ¡o lÃ  con ChatBot cá»§a há» cÃ³ thá»ƒ nhÃ¬n, nghe, vÃ  nÃ³i Ä‘Æ°á»£c (https://openai.com/blog/chatgpt-can-now-see-hear-and-speak), Ä‘iá»u nÃ y cÅ©ng thÃºc Ä‘áº©y mÃ¬nh thá»­ nghiÃªn cá»©u xem model GPT2 cÃ³ thá»ƒ nháº­n diá»‡n Ä‘Æ°á»£c hÃ¬nh áº£nh khÃ´ng. VÃ  mÃ¬nh Ä‘Ã£ thá»­ fine-turn model'huggingface.co/nlpconnect/vit-gpt2-image-captioning' Ä‘á»ƒ nháº­n diá»‡n Ä‘Æ°á»£c hÃ¬nh áº£nh vÃ  tráº£ lá»i báº±ng Tiáº¿ng Viá»‡t. Káº¿t quáº£ khÃ¡ tá»‘t nhÆ° sau:

Result:
- model_name = 'nlpconnect/vit-gpt2-image-captioning'
- lr=5e-4
- (3.083s) Epoch 15, Loss 0.033
- Answer: ÄÃ¢y lÃ  cá» Viá»‡t Nam!

![alt text](https://github.com/Mr-Jack-Tung/oneChatGPT/blob/main/oneChatbot-vit_Screenshot%202023-10-15%20at%208.26%20PM.png)

