# oneChatGPT
- oneChatbot_gpt2-vietnamese_fine-tune.py
- Author: Mr.Jack _ C√¥ng ty www.BICweb.vn
- Date: 24 August 2023

chatGPT si√™u si√™u nh·ªè, hu·∫•n luy·ªán ch·ªâ v·ªõi 1 c√¢u duy nh·∫•t, v√† ch·ªâ trong 1 ph√∫t (chatGPT super super tiny ... training with only one sentence dataset in one minute !)

"V√†o ng√†y 21/08/2023, C√¥ng ty C·ªï ph·∫ßn VinBigdata c√¥ng b·ªë x√¢y d·ª±ng th√†nh c√¥ng m√¥ h√¨nh ng√¥n ng·ªØ l·ªõn ti·∫øng Vi·ªát, ƒë·∫∑t n·ªÅn m√≥ng cho vi·ªác x√¢y d·ª±ng c√°c gi·∫£i ph√°p t√≠ch h·ª£p AI t·∫°o sinh..." 
https://genk.vn/vinbigdata-phat-trien-cong-nghe-ai-tao-sinh-se-som-cho-ra-mat-chatgpt-phien-ban-viet-20230821140700664.chn

ƒê√¢y c≈©ng c√≥ th·ªÉ coi l√† m·ªôt s·ª± ki·ªán l·ªõn c·ªßa d√¢n ng√†nh IT n√≥i chung v√† d√¢n l·∫≠p tr√¨nh "ng√†nh" chatGPT n√≥i ri√™ng, v√† ch·∫Øc c√≥ l·∫Ω "d√¢n ng√†nh" n√†o c≈©ng mong mu·ªën l√†m ƒë∆∞·ª£c ra m·ªôt em chatGPT nh∆∞ v·∫≠y ^^

Nh∆∞ng ƒë·ªëi v·ªõi k·ªπ s∆∞ l·∫≠p tr√¨nh khi m·ªõi b∆∞·ªõc v√†o th·∫ø gi·ªõi chatGPT th√¥ng th∆∞·ªùng s·∫Ω c√≥ nh·ªØng bƒÉn khoƒÉn sau:
1. M√¨nh c√≥ th·ªÉ tri·ªÉn khai ƒë∆∞·ª£c 1 em chatGPT ch·∫°y ƒë∆∞·ª£c ·ªü nh√† kh√¥ng?
2. C·∫ßn chu·∫©n b·ªã m√°y m√≥c c·∫•u h√¨nh ph·∫£i m·∫°nh c·ª° n√†o?
3. Kh·ªëi d·ªØ li·ªáu chu·∫©n b·ªã hu·∫•n luy·ªán l·ªõn ƒë·∫øn ƒë√¢u?
4. Ti·∫øng Vi·ªát th√¨ c√≥ kh√≥ hu·∫•n luy·ªán kh√¥ng?
5. Ph∆∞∆°ng ph√°p hu·∫•n luy·ªán ra sao?
6. Th·ªùi gian hu·∫•n luy·ªán trong bao l√¢u? 
7. ƒê·ªô ch√≠nh x√°c c√¢u tr·∫£ l·ªùi ra sao?
8. Bao gi·ªù s·∫Ω th·ª±c hi·ªán ƒë∆∞·ª£c ƒëi·ªÅu ƒë√≥?

==> Th√¥ng th∆∞·ªùng th√¨ c√¢u tr·∫£ l·ªùi s·∫Ω l√† ... Kh√¥ng bi·∫øt ^^


V√¨ v·∫≠y m√† h√¥m nay m√¨nh chia s·∫ª v·ªõi c√°c b·∫°n m·ªôt em chatGPT si√™u.. si√™u.. si√™u nh·ªè, ƒë·ªÉ c√°c b·∫°n c√πng t√¨m hi·ªÉu v√† ch∆°i v·ªõi em n√≥ nh√© ^^

- M·ª•c ƒë√≠ch: Nghi√™n c·ª©u h·ªçc t·∫≠p
- Ng√¥n ng·ªØ l·∫≠p tr√¨nh: Python
- ƒê·ªô d√†i m√£ ngu·ªìn: 55 d√≤ng code ^^
- Model pretrained: GPT2

- Ng√¥n ng·ªØ hu·∫•n luy·ªán: Ti·∫øng Vi·ªát
- D·ªØ li·ªáu hu·∫•n luy·ªán: Ch·ªâ 01 c√¢u duy nh·∫•t ^^
- M√°y hu·∫•n luy·ªán: 01 laptop sinh vi√™n
- Th·ªùi gian hu·∫•n luy·ªán: 01 ph√∫t
- ƒê·ªô tr·∫£ l·ªùi ch√≠nh x√°c: 100%

ƒê·ªÉ th·ª≠ nghi·ªám h√£y download file v√† ch·∫°y c√¢u l·ªánh:
$ python oneChatbot_gpt2-vietnamese_fine-tune.py

![alt text](https://github.com/Mr-Jack-Tung/oneChatGPT/blob/main/oneChatbot_Screenshot%202023-08-24%20at%2011.30.png)

Hy v·ªçng ƒëi·ªÅu n√†y s·∫Ω gi√∫p c√°c b·∫°n th√™m t·ª± tin tr√™n con ƒë∆∞·ªùng l·∫≠p tr√¨nh chinh ph·ª•c chatGPT nh√©! ^^

------------------------------
**Update**: Monday,25/09/2023 ~> Bao nhi√™u Parameters l√† ƒë·ªß ƒë·ªÉ fine-tune 1 c√¢u ti·∫øng Vi·ªát ch√≠nh x√°c ?

M√¨nh ƒë√£ th·ª≠ fine-tune v·ªõi model 'huggingface.co/roneneldan/TinyStories-33M', ch·ªâ v·ªõi 4 x GPTNeoBlock(features=768), c√≥ s·ªë l∆∞·ª£ng tham s·ªë l√† 33 tri·ªáu, nh·ªè h∆°n nhi·ªÅu so v·ªõi model gpt2 (124M), ƒë∆∞·ª£c ƒë√°nh gi√° l√† c√≥ ch·∫•t l∆∞·ª£ng kh√° t·ªët v·ªõi t·ªëc ƒë·ªô train nhanh h∆°n (https://arxiv.org/abs/2305.07759), nh∆∞ng khi th·ª≠ nghi·ªám th√¨ k·∫øt qu·∫£ c≈©ng ·ªïn v·ªõi model 'TinyStories-33M', c√≤n c√°c model v·ªõi s·ªë l∆∞·ª£ng params √≠t h∆°n (nh∆∞ model 1M, 3M, 8M, 21M) th√¨ kh√¥ng ok ^^

Update code:
- from transformers import AutoTokenizer, AutoModelForCausalLM
- model = AutoModelForCausalLM.from_pretrained('roneneldan/TinyStories-33M')
- tokenizer = AutoTokenizer.from_pretrained('EleutherAI/gpt-neo-125M')

Result:
- model_name = 'roneneldan/TinyStories-33M'
- lr=5e-4
- (0.665s) Epoch 29, Loss 0.115172
- Question: Xin ch√†o Answer: C√¥ng ty BICweb k√≠nh ch√†o qu√Ω kh√°ch!

With Emoji:
- model_name = 'roneneldan/TinyStories-33M'
- lr=6e-4
- qa_pair = 'Question: Xin ch√†o Answer: C√¥ng ty BICweb k√≠nh ch√†o qu√Ω kh√°ch ü§ó.'
- (0.662s) Epoch 49, Loss 0.099960
- Question: Xin ch√†o Answer: C√¥ng ty BICweb k√≠nh ch√†o qu√Ω kh√°ch ü§ó
